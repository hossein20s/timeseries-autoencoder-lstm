{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: Predicting churn with Apache MXNet and Gluon\n",
    "\n",
    "This notebook is designed to be a quick primer on Apache MXNet and Gluon while solving a churn prediction use case\n",
    "\n",
    "### Problem\n",
    "\n",
    "Service providers have historical records on customer loyalty and track how likely users are going to continue to use the service. We can use this historical information to construct a model to predict if the user is going to leave (churn) or continue to use the service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "To solve this problem we are going to use a technique known as logistic regression. Its used when the dependent variable is categorical. In this problem we are predicting if the user will churn or not, hence we'll use a binary logistic regression which is the binary version of the more generalized multiclass logistic regression. For further reading check the wikipedia [article](https://en.wikipedia.org/wiki/Multinomial_logistic_regression)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data\n",
    "\n",
    "The dataset I use is publicly available and was mentioned in the book “Discovering Knowledge in Data” by Daniel T. Larose. \n",
    "It is attributed by the author to the University of California Irvine Repository of Machine Learning Datasets, \n",
    "and can be downloaded from the author’s website [here](http://www.dataminingconsultant.com/data/churn.txt) in .csv format.\n",
    "\n",
    "A modified version is provided in the data/ folder for convinience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import logging\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)  # Config the logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "There are many factors (or features) that we think are indicative of customer churn. For simplicity we are going to use the last 5 features namely -- Night Charge, Intl Mins, Intl Calls, Intl Charge, CustServ Calls as the indicator for churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State,Account Length,Area Code,Phone,Int'l Plan,VMail Plan,VMail Message,Day Mins,Day Calls,Day Charge,Eve Mins,Eve Calls,Eve Charge,Night Mins,Night Calls,Night Charge,Intl Mins,Intl Calls,Intl Charge,CustServ Calls,Churn?\r",
      "\r\n",
      "KS,128,415,382-4657,no,yes,25,265.100000,110,45.070000,197.400000,99,16.780000,244.700000,91,11.010000,10.000000,3,2.700000,1,False.\r",
      "\r\n",
      "OH,107,415,371-7191,no,yes,26,161.600000,123,27.470000,195.500000,103,16.620000,254.400000,103,11.450000,13.700000,3,3.700000,1,False.\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 churn.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets split into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3330, 5) (3330, 1)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Data fields in the CSV\n",
    "\n",
    "#State,Account Length,Area Code,Phone,Int'l Plan,VMail Plan, VMail Message,Day Mins,Day Calls,\n",
    "#Day Charge,Eve Mins,Eve Calls,Eve Charge,Night Mins,Night Calls,\n",
    "#Night Charge,Intl Mins,Intl Calls,Intl Charge,CustServ Calls,Churn?\n",
    "\n",
    "dataframe = pd.read_csv('churn.txt', engine='python', skipfooter=3)\n",
    "dataset = dataframe.values\n",
    "x_data = dataset[:, -6:-1] # use a subset as features\n",
    "\n",
    "# convert the last field in to [0,1] from False/True \n",
    "y_data = np.array([[0 if d == 'False.' else 1 for d in dataset[:, [-1]]]]).T \n",
    "\n",
    "print(x_data.shape, y_data.shape)\n",
    "print(type(x_data), type(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2331 999\n",
      "2331 999\n"
     ]
    }
   ],
   "source": [
    "sample_num = x_data.shape[0]\n",
    "dimension = x_data.shape[1]\n",
    "batch_size = 32\n",
    "\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_x, test_x = x_data[0:train_size,:], x_data[train_size:len(x_data),:]\n",
    "train_y, test_y = y_data[0:train_size,:], y_data[train_size:len(y_data),:]\n",
    "\n",
    "print(len(train_x), len(test_x))\n",
    "print(len(train_y), len(test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to look at [NDArrays](https://github.com/zackchase/mxnet-the-straight-dope/blob/master/chapter01_crashcourse/ndarray.ipynb) in MXNet and Gluon. We'll use this extensively in all our notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Logistic Regression Model -- Symbolic Apache MXNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Train-acc=0.837757\n",
      "INFO:root:Epoch[0] Time cost=0.055\n",
      "INFO:root:Epoch[1] Train-acc=0.864726\n",
      "INFO:root:Epoch[1] Time cost=0.053\n",
      "INFO:root:Epoch[2] Train-acc=0.865154\n",
      "INFO:root:Epoch[2] Time cost=0.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/dev/environments/project_env/lib/python3.6/site-packages/mxnet/module/base_module.py:502: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  allow_missing=allow_missing, force_init=force_init)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch[3] Train-acc=0.865154\n",
      "INFO:root:Epoch[3] Time cost=0.062\n",
      "INFO:root:Epoch[4] Train-acc=0.865154\n",
      "INFO:root:Epoch[4] Time cost=0.050\n",
      "INFO:root:Epoch[5] Train-acc=0.864726\n",
      "INFO:root:Epoch[5] Time cost=0.050\n",
      "INFO:root:Epoch[6] Train-acc=0.864726\n",
      "INFO:root:Epoch[6] Time cost=0.054\n",
      "INFO:root:Epoch[7] Train-acc=0.864298\n",
      "INFO:root:Epoch[7] Time cost=0.052\n",
      "INFO:root:Epoch[8] Train-acc=0.864726\n",
      "INFO:root:Epoch[8] Time cost=0.054\n",
      "INFO:root:Epoch[9] Train-acc=0.864726\n",
      "INFO:root:Epoch[9] Time cost=0.051\n",
      "INFO:root:Epoch[10] Train-acc=0.864298\n",
      "INFO:root:Epoch[10] Time cost=0.050\n",
      "INFO:root:Epoch[11] Train-acc=0.865154\n",
      "INFO:root:Epoch[11] Time cost=0.056\n",
      "INFO:root:Epoch[12] Train-acc=0.864298\n",
      "INFO:root:Epoch[12] Time cost=0.056\n",
      "INFO:root:Epoch[13] Train-acc=0.866438\n",
      "INFO:root:Epoch[13] Time cost=0.055\n",
      "INFO:root:Epoch[14] Train-acc=0.865582\n",
      "INFO:root:Epoch[14] Time cost=0.055\n",
      "INFO:root:Epoch[15] Train-acc=0.866866\n",
      "INFO:root:Epoch[15] Time cost=0.055\n",
      "INFO:root:Epoch[16] Train-acc=0.865154\n",
      "INFO:root:Epoch[16] Time cost=0.058\n",
      "INFO:root:Epoch[17] Train-acc=0.864298\n",
      "INFO:root:Epoch[17] Time cost=0.057\n",
      "INFO:root:Epoch[18] Train-acc=0.865154\n",
      "INFO:root:Epoch[18] Time cost=0.066\n",
      "INFO:root:Epoch[19] Train-acc=0.865582\n",
      "INFO:root:Epoch[19] Time cost=0.066\n"
     ]
    }
   ],
   "source": [
    "# Lets build the Logistic Regression Model\n",
    "\n",
    "# Placeholders for X & y\n",
    "data = mx.sym.Variable(\"data\")\n",
    "target = mx.sym.Variable(\"target\")\n",
    "\n",
    "fc = mx.sym.FullyConnected(data=data, num_hidden=1, name='fc')\n",
    "pred = mx.sym.LogisticRegressionOutput(data=fc, label=target)\n",
    "\n",
    "# Contstruct the module object\n",
    "model = mx.mod.Module(symbol=pred,\n",
    "                    data_names=['data'],\n",
    "                    label_names=['target'],\n",
    "                    context=mx.cpu(0))\n",
    "\n",
    "# bind the data and label shapes\n",
    "# you can also use train_iter.provide_data & .provide_label\n",
    "model.bind(data_shapes=[mx.io.DataDesc(name='data', shape=(batch_size, dimension), layout='NC')],\n",
    "         label_shapes=[mx.io.DataDesc(name='target', shape=(batch_size, 1), layout='NC')])\n",
    "model.init_params(initializer=mx.init.Normal(sigma=0.01))\n",
    "model.init_optimizer(optimizer='sgd', \n",
    "            optimizer_params={'learning_rate': 1E-3, 'momentum': 0.9})\n",
    "\n",
    "# Build the data iterator\n",
    "train_iter = mx.io.NDArrayIter(train_x, train_y, batch_size,\n",
    "                               shuffle=True, label_name='target')\n",
    "\n",
    "\n",
    "# Create a custom metric\n",
    "metric = mx.metric.CustomMetric(feval=lambda labels, \n",
    "                                pred: ((pred > 0.5) == labels).mean(),\n",
    "                                name=\"acc\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data=train_iter, eval_metric=metric, num_epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8328328328328328\n"
     ]
    }
   ],
   "source": [
    "# Test data iterator\n",
    "test_iter = mx.io.NDArrayIter(test_x, test_y, batch_size, shuffle=False, label_name=None)\n",
    "\n",
    "pred_class = (fc > 0) # de\n",
    "test_model = mx.mod.Module(symbol=pred_class,\n",
    "                         data_names=['data'],\n",
    "                         label_names=None,\n",
    "                         context=mx.cpu(0))\n",
    "test_model.bind(data_shapes=[mx.io.DataDesc(name='data', shape=(batch_size, dimension), layout='NC')],\n",
    "              label_shapes=None,\n",
    "              for_training=False,\n",
    "              shared_module=model)\n",
    "out = test_model.predict(eval_data=test_iter)\n",
    "acc = np.sum(out.asnumpy() == test_y)/ (len(test_y)*1.0)\n",
    "\n",
    "#print(out.asnumpy())\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "Along with accuracy we'd like to visualize the evaluation with four important statistics relative to the total number of predictions: the percentage of true negatives (TN), true positives (TP), false negatives (FN), and false positives (FP). These stats are often presented in the form of a , as follows.\n",
    "\n",
    "![.](o_churn_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[830   0]\n",
      " [167   2]]\n",
      "169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_y, out.asnumpy()))\n",
    "print(np.sum(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression with Gluon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "\n",
    "ctx = mx.cpu()\n",
    "\n",
    "N_CLASS = 1\n",
    "\n",
    "# Define the model\n",
    "net = gluon.nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Dense(1))\n",
    "\n",
    "# init params\n",
    "net.collect_params().initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n",
    "\n",
    "# optimizer\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "\n",
    "# Define Data Iterators\n",
    "test_iter = mx.io.NDArrayIter(train_x, train_y, batch_size, shuffle=True, label_name=None)\n",
    "test_iter = mx.io.NDArrayIter(test_x, test_y, batch_size, shuffle=False, label_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Network\n",
    "\n",
    "ctx = mx.cpu()\n",
    "net = gluon.nn.Dense(1)\n",
    "net.collect_params().initialize(mx.init.Normal(sigma=1.), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "\n",
    "def logistic(z):\n",
    "    return 1. / (1. + nd.exp(-z))\n",
    "\n",
    "def log_loss(output, y):\n",
    "    yhat = logistic(output)\n",
    "    return  - nd.nansum(  y * nd.log(yhat) + (1-y) * nd.log(1-yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training we use the autograd module to take gradients. See this [link](https://github.com/zackchase/mxnet-the-straight-dope/blob/master/chapter01_crashcourse/autograd.ipynb) for details on how it works\n",
    "\n",
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 1939.530174255371\n",
      "Epoch 1, loss: 0\n",
      "Epoch 2, loss: 0\n",
      "Epoch 3, loss: 0\n",
      "Epoch 4, loss: 0\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "loss_sequence = []\n",
    "num_examples = len(train_x)\n",
    "train_iter.reset()\n",
    "for e in range(epochs):\n",
    "    cumulative_loss = 0\n",
    "    for i, batch in enumerate(train_iter):\n",
    "        data = batch.data[0].as_in_context(ctx)\n",
    "        label = batch.label[0].as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = log_loss(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "        cumulative_loss += nd.sum(loss).asscalar()\n",
    "    print(\"Epoch %s, loss: %s\" % (e, cumulative_loss ))\n",
    "    loss_sequence.append(cumulative_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'average loss')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.axes._base:update_title_pos\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/dev/environments/project_env/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=14.0 to DejaVu Sans ('/opt/dev/environments/project_env/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n",
      "DEBUG:matplotlib.axes._base:update_title_pos\n",
      "DEBUG:matplotlib.axes._base:update_title_pos\n",
      "DEBUG:matplotlib.axes._base:update_title_pos\n",
      "DEBUG:matplotlib.axes._base:update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the convergence of the estimated loss function \n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(num=None,figsize=(8, 6))\n",
    "plt.plot(loss_sequence)\n",
    "\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xlabel('epoch',fontsize=14)\n",
    "plt.ylabel('average loss',fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.851 (850.0/999)\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0.0\n",
    "num_total = len(test_x)\n",
    "pred_out = []\n",
    "test_iter.reset()\n",
    "for i, batch in enumerate(test_iter):\n",
    "    data = batch.data[0].as_in_context(ctx)\n",
    "    label = batch.label[0].as_in_context(ctx)\n",
    "    output = net(data)\n",
    "    prediction = (nd.sign(output) + 1) / 2\n",
    "    pred_out.append(prediction.asnumpy())\n",
    "    num_correct += nd.sum(prediction == label)\n",
    "print(\"Accuracy: %0.3f (%s/%s)\" % (num_correct.asscalar()/num_total, num_correct.asscalar(), num_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[829   1]\n",
      " [169   0]]\n",
      "169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_y, np.vstack(pred_out)[:len(test_y)]))\n",
    "print(np.sum(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
