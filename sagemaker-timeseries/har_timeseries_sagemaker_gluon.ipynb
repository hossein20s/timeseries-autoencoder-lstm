{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Timeseries SageMaker Template with Gluon\n",
    "\n",
    "This is a template to run the human activity recognition notebook. Refer the `smartphone_human_activity_classification_gluon.ipynb` for non sagemaker version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from mxnet import gluon\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Package Data\n",
    "\n",
    "1. Load your train and test data as numpy arrays\n",
    "2. Package data as a pickle file and upload to S3\n",
    "\n",
    "by doing this, we can use the generic_ts.py file to run any timeseries classification task with SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def get_labels_from_csv(path):\n",
    "    values = []\n",
    "    with open(path, 'rb') as csvfile:\n",
    "        rd = csv.reader(csvfile, delimiter=',')\n",
    "        for row in rd:\n",
    "            values.append(float(row[0]))\n",
    "    return np.array(values).astype('float32')\n",
    "\n",
    "\n",
    "INPUT_SIGNAL_TYPES = [\n",
    "    \"body_acc_x_\",\n",
    "    \"body_acc_y_\",\n",
    "    \"body_acc_z_\",\n",
    "    \"body_gyro_x_\",\n",
    "    \"body_gyro_y_\",\n",
    "    \"body_gyro_z_\",\n",
    "    \"total_acc_x_\",\n",
    "    \"total_acc_y_\",\n",
    "    \"total_acc_z_\"\n",
    "]\n",
    "\n",
    "LABELS = [\n",
    "    \"WALKING\",\n",
    "    \"WALKING_UPSTAIRS\",\n",
    "    \"WALKING_DOWNSTAIRS\",\n",
    "    \"SITTING\",\n",
    "    \"STANDING\",\n",
    "    \"LAYING\"\n",
    "]\n",
    "\n",
    "\n",
    "path = 'ts_data'\n",
    "\n",
    "train = [path + \"/train/%strain.txt\" % signal for signal in INPUT_SIGNAL_TYPES]\n",
    "test = [path + \"/test/%stest.txt\" % signal for signal in INPUT_SIGNAL_TYPES]\n",
    "\n",
    "\n",
    "def load_data(files):\n",
    "    arr = []\n",
    "    for fname in files:\n",
    "        with open(fname, 'r') as f:\n",
    "            rows = [row.replace('  ', ' ').strip().split(' ') for row in f]\n",
    "            arr.append([np.array(ele, dtype=np.float32) for ele in rows])\n",
    "    return np.transpose(np.array(arr), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7352, 128, 9), (2947, 128, 9))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = load_data(train)\n",
    "X_test = load_data(test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_path = path + \"/train/y_train.txt\"\n",
    "y_train = get_labels_from_csv(y_train_path)\n",
    "\n",
    "y_test_path = path + \"/test/y_test.txt\"\n",
    "y_test = get_labels_from_csv(y_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump([X_train, y_train], open('train.pkl', 'wb'))\n",
    "pickle.dump([X_test, y_test], open('test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2947, 128, 9), (2947,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t, y_t = pickle.load(open('pkl_data/test/test.pkl', \"rb\"))\n",
    "X_t.shape, y_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- end of data transformation, loading and packaging ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the data\n",
    "\n",
    "We use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value `inputs` identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='pkl_data', key_prefix='data/har_pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## execute cell below to view the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat generic_ts.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training script on SageMaker\n",
    "\n",
    "The ```MXNet``` class allows us to run our training function on SageMaker infrastructure. We need to configure it with our training script, an IAM role, the number of training instances, and the training instance type. In this case we will run our training job on a single m4.xlarge instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = MXNet(\"generic_ts.py\", \n",
    "          role=role, \n",
    "          train_instance_count=1, \n",
    "          train_instance_type=\"ml.p2.xlarge\",\n",
    "          hyperparameters={'batch_size': 32, \n",
    "                         'epochs': 1, \n",
    "                         'learning_rate': 0.01, \n",
    "                         'momentum': 0.9, \n",
    "                         'log_interval': 100,\n",
    "                         'n_out': len(LABELS),\n",
    "                         'num_gpus': 1\n",
    "                          })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our `MXNet` object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-py2-gpu-2018-01-29-07-20-17-950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................\n",
      "\u001b[31mexecuting startup script (first run)\u001b[0m\n",
      "\u001b[31m2018-01-29 07:27:06,741 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-01-29 07:27:06,741 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-01-29 07:27:09,477 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'enable_cloudwatch_metrics': False, 'available_gpus': 1, 'channels': {u'training': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}}, '_ps_verbose': 0, 'resource_config': {u'current_host': u'algo-1', u'hosts': [u'algo-1']}, 'user_script_name': u'generic_ts.py', 'input_config_dir': '/opt/ml/input/config', 'channel_dirs': {u'training': u'/opt/ml/input/data/training'}, 'code_dir': '/opt/ml/code', 'output_data_dir': '/opt/ml/output/data/', 'output_dir': '/opt/ml/output', 'model_dir': '/opt/ml/model', 'hyperparameters': {u'sagemaker_program': u'generic_ts.py', u'num_gpus': 1, u'learning_rate': 0.01, u'log_interval': 100, u'epochs': 1, u'batch_size': 32, u'sagemaker_region': u'us-west-2', u'sagemaker_enable_cloudwatch_metrics': False, u'n_out': 6, u'sagemaker_job_name': u'sagemaker-mxnet-py2-gpu-2018-01-29-07-20-17-950', u'sagemaker_container_log_level': 20, u'momentum': 0.9, u'sagemaker_submit_directory': u's3://sagemaker-us-west-2-209028685534/sagemaker-mxnet-py2-gpu-2018-01-29-07-20-17-950/source/sourcedir.tar.gz'}, 'hosts': [u'algo-1'], '_ps_port': 8000, 'user_script_archive': u's3://sagemaker-us-west-2-209028685534/sagemaker-mxnet-py2-gpu-2018-01-29-07-20-17-950/source/sourcedir.tar.gz', '_scheduler_host': u'algo-1', 'sagemaker_region': u'us-west-2', 'input_dir': '/opt/ml/input', '_scheduler_ip': '10.32.0.4', 'current_host': u'algo-1', 'container_log_level': 20, 'available_cpus': 4, 'base_dir': '/opt/ml'}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-west-2-209028685534/sagemaker-mxnet-py2-gpu-2018-01-29-07-20-17-950/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-01-29 07:27:09,690 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-01-29 07:27:09,832 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-01-29 07:27:10,150 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.us-west-2.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-01-29 07:27:10,250 INFO - mxnet_container.train - Starting distributed training task\u001b[0m\n",
      "\u001b[31mcpu(0)\u001b[0m\n",
      "\u001b[31m[Epoch 0] [Batch 0/229] Loss: 1.78374, Batch acc: 0.34375\u001b[0m\n",
      "\u001b[31m[Epoch 0] [Batch 100/229] Loss: 1.40561, Batch acc: 0.40625\u001b[0m\n",
      "\u001b[31m[Epoch 0] [Batch 200/229] Loss: 1.05586, Batch acc: 0.37500\u001b[0m\n",
      "\u001b[31mEpoch 0. Loss: 0.97863 Train Acc: ('accuracy', 0.5139192139737991) Test Acc: ('accuracy', 0.48471467391304346)\u001b[0m\n",
      "\u001b[31msaving the model\u001b[0m\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "m.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p27",
   "language": "python",
   "name": "conda_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
