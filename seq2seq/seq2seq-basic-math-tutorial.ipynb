{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Seq2Seq MXNet Addition Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This notebook walks through a neural network implementation to perform basic math operators like addition and multiplication. The objective is to show you can convert from a given set of input sequences to an output sequence.\n",
    "\n",
    "Its inspired by serveral blogs, but mainly from this paper - \"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "\n",
    "- Needs GPU, run on Amazon ec2 p2,p3,g2/g3 instance with Deep Learning AMI.\n",
    "\n",
    "For setting up an deep learning environment on AWS using Deep Learning AMI, please read [this post on AWS AI Blog](https://aws.amazon.com/blogs/ai/the-aws-deep-learning-ami-now-with-ubuntu/) for detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence modeling basics\n",
    "\n",
    "### What is sequence modeling?\n",
    "\n",
    "![](https://indico.io/blog/wp-content/uploads/2016/04/seq-nathan-fig3a.jpg)\n",
    "\n",
    "### Encoder - Decoder\n",
    "\n",
    "\n",
    "![](https://indico.io/blog/wp-content/uploads/2016/04/seq-nathan-figure3_b.jpg)\n",
    "\n",
    "Encoder transforms the input in to a hidden state. This can now be translated or converted in to any desirable form. The decoder tries to\n",
    "predict the next word in the outpute (decoder) sequence, given the current word in the decoder sequence and the context from the encoder sequence.\n",
    "\n",
    "### What problems can we solve with this\n",
    "\n",
    "- Language translation\n",
    "- image caption\n",
    "- sequence conversion\n",
    "\n",
    "\n",
    "<small>img src: https://indico.io/blog/sequence-modeling-neuralnets-part1/ </small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 4\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import mxnet.ndarray as nd\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "random.seed(10)\n",
    "\n",
    "n_samples = 1000 # Training Set\n",
    "n_numbers = 3 # how many numbers do we want to operate on\n",
    "\n",
    "largest = 10 #largest INT \n",
    "\n",
    "# Character set \n",
    "character_set = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '*', ' ']\n",
    "data_dim = len(character_set)  # size of our vocab; also one hot encoding size\n",
    "\n",
    "input_seq_length = 8 # max_digit_len + n_operators = n_numbers*2 + 2\n",
    "output_seq_length = n_numbers + 1 #MAX Output Length\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "print(input_seq_length, output_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Lets define a helper function to generate our training data, in this case we'll generate sum pairs\n",
    "\n",
    "(ex: 5+4+9 = 18, 1+4+2 = 7, 3*2*5=30 etc)\n",
    "\n",
    "We will also encode these with our character_set or character set defined above. for example character_set[1] is \"1\", character_set[2] is 2 and so on for all the numbers, and we'll define the operators \"+\" & \"*\" as indices after that. Space \" \" is used for padding. We'll later convert this to one-hot encoding \n",
    "[<LINK>?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000\n",
      "(1000, 8) (1000, 4)\n"
     ]
    }
   ],
   "source": [
    "def get_sum_pairs(n_examples):\n",
    "    inputs, labels = list(), list()\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(character_set)) # lookup table\n",
    "\n",
    "    for i in range(n_examples):\n",
    "        lhs = [random.randint(1, largest) for _ in range(n_numbers)]\n",
    "        op = random.choice(['+', '*']) \n",
    "        if op == '+':\n",
    "            rhs = sum(lhs)\n",
    "        elif op == '*':\n",
    "            rhs = 1\n",
    "            for l in lhs:\n",
    "                rhs *= l\n",
    "\n",
    "        #LHS\n",
    "        lhs = [str(l) for l in lhs]\n",
    "        strng = \"*\".join(lhs) if op == \"*\" else \"+\".join(lhs)  # + or * only\n",
    "        padded_strng = \"%*s\"  % (input_seq_length, strng)\n",
    "        inp_encoded = [char_to_int[char] for char in padded_strng]\n",
    "        \n",
    "        #RHS\n",
    "        padded_strng = \"%*s\"  % (output_seq_length, str(rhs))\n",
    "        out_encoded = [char_to_int[char] for char in padded_strng]\n",
    "        inputs.append(inp_encoded)\n",
    "        labels.append(out_encoded)\n",
    "        \n",
    "    print(len(inputs), len(labels))\n",
    "    return np.array(inputs), np.array(labels)\n",
    " \n",
    "\n",
    "dataX, dataY = get_sum_pairs(n_samples)\n",
    "\n",
    "print(dataX.shape, dataY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataDesc[data,(32, 8L),<type 'numpy.float32'>,NCHW]] [DataDesc[target,(32, 4L),<type 'numpy.float32'>,NCHW]]\n"
     ]
    }
   ],
   "source": [
    "## Lets define the Iterator\n",
    "train_iter = mx.io.NDArrayIter(data=dataX, label=dataY,\n",
    "                                 data_name=\"data\", label_name=\"target\",\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True)\n",
    "\n",
    "print(train_iter.provide_data, train_iter.provide_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Lets implement a encoder/decoder with LSTM Model\n",
    "\n",
    "Note that we'll use mx.sym.one_hot symbol to convert our input in to one-hot encoding before it gets fed in to the encoder layer of the LSTM\n",
    "\n",
    "To get a primer on LSTMs and RNNs you can refer to these blogs\n",
    "\n",
    "[LSTM basics](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) \n",
    "\n",
    "[encoder/decoder](http://machinelearningmastery.com/learn-add-numbers-seq2seq-recurrent-neural-networks/) \n",
    "\n",
    "[timeseries modeling](https://github.com/sunilmallya/mxnet-notebooks/blob/master/python/tutorials/aws_spot_price_predict_lstm.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### why one hot ?\n",
    "\n",
    "In general most ML agorithms don't understand the label data directly. They like input/output variables to be numbers.\n",
    "\n",
    "For categorical data where there is no ordering, its not desirable to let the model assume any kind of ordering. One-hot encoding can help establish this and is a more desirable format for the neural network to work on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = mx.sym.var('data')  # Shape: (N, T)\n",
    "target = mx.sym.var('target')  # Shape: (N, T)\n",
    "\n",
    "# 2 Layer LSTM \n",
    "# get_next_state = return the states that can be used as starting states next time\n",
    "\n",
    "lstm1 = mx.rnn.FusedRNNCell(num_hidden=32, prefix=\"lstm1_\", get_next_state=True)\n",
    "lstm2 = mx.rnn.FusedRNNCell(num_hidden=32, prefix=\"lstm2_\", get_next_state=False)\n",
    "\n",
    "# In the layout, 'N' represents batch size, 'T' represents sequence length,\n",
    "# and 'C' represents the number of dimensions in hidden states.\n",
    "  \n",
    "# one hot encode \n",
    "data_one_hot = mx.sym.one_hot(data, depth=data_dim) # Shape: (N, T, C)\n",
    "data_one_hot = mx.sym.transpose(data_one_hot, axes=(1, 0, 2)) # Shape: (T, N, C)\n",
    "\n",
    "# Note that when unrolling, if 'merge_outputs'== True, the 'outputs' is merged into a single symbol\n",
    "# encoder  (with repeat vector)\n",
    "_, encode_state = lstm1.unroll(length=input_seq_length, inputs=data_one_hot, layout=\"TNC\")\n",
    "encode_state_h = mx.sym.broadcast_to(encode_state[0], shape=(output_seq_length, 0, 0)) #Shape: (T,N,C); use ouput seq shape\n",
    "\n",
    "# decoder\n",
    "decode_out, _ = lstm2.unroll(length=output_seq_length, inputs=encode_state_h, layout=\"TNC\")\n",
    "decode_out = mx.sym.reshape(decode_out, shape=(-1, batch_size))\n",
    "\n",
    "# logits out\n",
    "logits = mx.sym.FullyConnected(decode_out, num_hidden=data_dim, name=\"logits\")\n",
    "logits = mx.sym.reshape(logits, shape=(output_seq_length, -1, data_dim))\n",
    "logits = mx.sym.transpose(logits, axes=(1, 0, 2))\n",
    "\n",
    "# Lets define a loss function: Convert Logits to softmax probabilities\n",
    "loss = mx.sym.mean(-mx.sym.pick(mx.sym.log_softmax(logits), target, axis=-1))\n",
    "loss = mx.sym.make_loss(loss)\n",
    "\n",
    "# visualize\n",
    "shape = {\"data\" : (batch_size, dataX[0].shape[0])}\n",
    "mx.viz.plot_network(loss, shape=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = mx.mod.Module(symbol=loss,\n",
    "                    data_names=['data'],\n",
    "                    label_names=['target'],\n",
    "                    context=mx.gpu())\n",
    "\n",
    "net.bind(data_shapes=train_iter.provide_data,\n",
    "            label_shapes=train_iter.provide_label)\n",
    "\n",
    "\n",
    "net.init_params(initializer=mx.init.Xavier())\n",
    "net.init_optimizer(optimizer=\"adam\",\n",
    "                   optimizer_params={'learning_rate': 1E-3,\n",
    "                                     'rescale_grad': 1.0},\n",
    "                   kvstore=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0001', 'cost =', '2.488914397')\n",
      "('Epoch:', '0002', 'cost =', '1.994357786')\n",
      "('Epoch:', '0003', 'cost =', '1.500532869')\n",
      "('Epoch:', '0004', 'cost =', '1.324073261')\n",
      "('Epoch:', '0005', 'cost =', '1.214142692')\n",
      "('Epoch:', '0006', 'cost =', '1.138869951')\n",
      "('Epoch:', '0007', 'cost =', '1.090947459')\n",
      "('Epoch:', '0008', 'cost =', '1.059179443')\n",
      "('Epoch:', '0009', 'cost =', '1.035796508')\n",
      "('Epoch:', '0010', 'cost =', '1.016810117')\n",
      "('Epoch:', '0011', 'cost =', '1.000326949')\n",
      "('Epoch:', '0012', 'cost =', '0.985143715')\n",
      "('Epoch:', '0013', 'cost =', '0.970109126')\n",
      "('Epoch:', '0014', 'cost =', '0.954816386')\n",
      "('Epoch:', '0015', 'cost =', '0.940555248')\n",
      "('Epoch:', '0016', 'cost =', '0.927457961')\n",
      "('Epoch:', '0017', 'cost =', '0.915424118')\n",
      "('Epoch:', '0018', 'cost =', '0.904117994')\n",
      "('Epoch:', '0019', 'cost =', '0.893924356')\n",
      "('Epoch:', '0020', 'cost =', '0.884643414')\n",
      "('Epoch:', '0021', 'cost =', '0.875751190')\n",
      "('Epoch:', '0022', 'cost =', '0.866442223')\n",
      "('Epoch:', '0023', 'cost =', '0.855614339')\n",
      "('Epoch:', '0024', 'cost =', '0.845102418')\n",
      "('Epoch:', '0025', 'cost =', '0.836023327')\n",
      "('Epoch:', '0026', 'cost =', '0.827650860')\n",
      "('Epoch:', '0027', 'cost =', '0.819720093')\n",
      "('Epoch:', '0028', 'cost =', '0.812093867')\n",
      "('Epoch:', '0029', 'cost =', '0.804657400')\n",
      "('Epoch:', '0030', 'cost =', '0.797355517')\n",
      "('Epoch:', '0031', 'cost =', '0.790122328')\n",
      "('Epoch:', '0032', 'cost =', '0.782863800')\n",
      "('Epoch:', '0033', 'cost =', '0.775509048')\n",
      "('Epoch:', '0034', 'cost =', '0.768035948')\n",
      "('Epoch:', '0035', 'cost =', '0.760366146')\n",
      "('Epoch:', '0036', 'cost =', '0.752487846')\n",
      "('Epoch:', '0037', 'cost =', '0.744514396')\n",
      "('Epoch:', '0038', 'cost =', '0.736518558')\n",
      "('Epoch:', '0039', 'cost =', '0.728559140')\n",
      "('Epoch:', '0040', 'cost =', '0.720658483')\n",
      "('Epoch:', '0041', 'cost =', '0.712863709')\n",
      "('Epoch:', '0042', 'cost =', '0.705363156')\n",
      "('Epoch:', '0043', 'cost =', '0.698144530')\n",
      "('Epoch:', '0044', 'cost =', '0.691238225')\n",
      "('Epoch:', '0045', 'cost =', '0.684640461')\n",
      "('Epoch:', '0046', 'cost =', '0.678288542')\n",
      "('Epoch:', '0047', 'cost =', '0.672106939')\n",
      "('Epoch:', '0048', 'cost =', '0.666023885')\n",
      "('Epoch:', '0049', 'cost =', '0.659970978')\n",
      "('Epoch:', '0050', 'cost =', '0.653902617')\n",
      "('Epoch:', '0051', 'cost =', '0.647836239')\n",
      "('Epoch:', '0052', 'cost =', '0.641831004')\n",
      "('Epoch:', '0053', 'cost =', '0.635928304')\n",
      "('Epoch:', '0054', 'cost =', '0.630131885')\n",
      "('Epoch:', '0055', 'cost =', '0.624413948')\n",
      "('Epoch:', '0056', 'cost =', '0.618731504')\n",
      "('Epoch:', '0057', 'cost =', '0.613041207')\n",
      "('Epoch:', '0058', 'cost =', '0.607311561')\n",
      "('Epoch:', '0059', 'cost =', '0.601547891')\n",
      "('Epoch:', '0060', 'cost =', '0.595815795')\n",
      "('Epoch:', '0061', 'cost =', '0.590219290')\n",
      "('Epoch:', '0062', 'cost =', '0.584642939')\n",
      "('Epoch:', '0063', 'cost =', '0.578758393')\n",
      "('Epoch:', '0064', 'cost =', '0.572766546')\n",
      "('Epoch:', '0065', 'cost =', '0.566945888')\n",
      "('Epoch:', '0066', 'cost =', '0.561364514')\n",
      "('Epoch:', '0067', 'cost =', '0.555902822')\n",
      "('Epoch:', '0068', 'cost =', '0.550481127')\n",
      "('Epoch:', '0069', 'cost =', '0.545070256')\n",
      "('Epoch:', '0070', 'cost =', '0.539666382')\n",
      "('Epoch:', '0071', 'cost =', '0.534263912')\n",
      "('Epoch:', '0072', 'cost =', '0.528724893')\n",
      "('Epoch:', '0073', 'cost =', '0.523083851')\n",
      "('Epoch:', '0074', 'cost =', '0.517615066')\n",
      "('Epoch:', '0075', 'cost =', '0.512382343')\n",
      "('Epoch:', '0076', 'cost =', '0.507289998')\n",
      "('Epoch:', '0077', 'cost =', '0.502243594')\n",
      "('Epoch:', '0078', 'cost =', '0.497220880')\n",
      "('Epoch:', '0079', 'cost =', '0.492260396')\n",
      "('Epoch:', '0080', 'cost =', '0.487400865')\n",
      "('Epoch:', '0081', 'cost =', '0.482630566')\n",
      "('Epoch:', '0082', 'cost =', '0.477913205')\n",
      "('Epoch:', '0083', 'cost =', '0.473237182')\n",
      "('Epoch:', '0084', 'cost =', '0.468613423')\n",
      "('Epoch:', '0085', 'cost =', '0.464061568')\n",
      "('Epoch:', '0086', 'cost =', '0.459603135')\n",
      "('Epoch:', '0087', 'cost =', '0.455253163')\n",
      "('Epoch:', '0088', 'cost =', '0.451008979')\n",
      "('Epoch:', '0089', 'cost =', '0.446859060')\n",
      "('Epoch:', '0090', 'cost =', '0.442785036')\n",
      "('Epoch:', '0091', 'cost =', '0.438768567')\n",
      "('Epoch:', '0092', 'cost =', '0.434804540')\n",
      "('Epoch:', '0093', 'cost =', '0.430904280')\n",
      "('Epoch:', '0094', 'cost =', '0.427085722')\n",
      "('Epoch:', '0095', 'cost =', '0.423359052')\n",
      "('Epoch:', '0096', 'cost =', '0.419804908')\n",
      "('Epoch:', '0097', 'cost =', '0.416616334')\n",
      "('Epoch:', '0098', 'cost =', '0.413816684')\n",
      "('Epoch:', '0099', 'cost =', '0.411366751')\n",
      "('Epoch:', '0100', 'cost =', '0.408692403')\n",
      "('Epoch:', '0101', 'cost =', '0.404526672')\n",
      "('Epoch:', '0102', 'cost =', '0.403477962')\n",
      "('Epoch:', '0103', 'cost =', '0.402641325')\n",
      "('Epoch:', '0104', 'cost =', '0.399008806')\n",
      "('Epoch:', '0105', 'cost =', '0.405350701')\n",
      "('Epoch:', '0106', 'cost =', '0.440097210')\n",
      "('Epoch:', '0107', 'cost =', '0.390448241')\n",
      "('Epoch:', '0108', 'cost =', '0.392393663')\n",
      "('Epoch:', '0109', 'cost =', '0.393922643')\n",
      "('Epoch:', '0110', 'cost =', '0.389112316')\n",
      "('Epoch:', '0111', 'cost =', '0.384141886')\n",
      "('Epoch:', '0112', 'cost =', '0.376845862')\n",
      "('Epoch:', '0113', 'cost =', '0.366916831')\n",
      "('Epoch:', '0114', 'cost =', '0.362284426')\n",
      "('Epoch:', '0115', 'cost =', '0.359305777')\n",
      "('Epoch:', '0116', 'cost =', '0.356625705')\n",
      "('Epoch:', '0117', 'cost =', '0.354157074')\n",
      "('Epoch:', '0118', 'cost =', '0.351745952')\n",
      "('Epoch:', '0119', 'cost =', '0.349395068')\n",
      "('Epoch:', '0120', 'cost =', '0.347076438')\n",
      "('Epoch:', '0121', 'cost =', '0.344786734')\n",
      "('Epoch:', '0122', 'cost =', '0.342521519')\n",
      "('Epoch:', '0123', 'cost =', '0.340276632')\n",
      "('Epoch:', '0124', 'cost =', '0.338047578')\n",
      "('Epoch:', '0125', 'cost =', '0.335829615')\n",
      "('Epoch:', '0126', 'cost =', '0.333618028')\n",
      "('Epoch:', '0127', 'cost =', '0.331407514')\n",
      "('Epoch:', '0128', 'cost =', '0.329191697')\n",
      "('Epoch:', '0129', 'cost =', '0.326961979')\n",
      "('Epoch:', '0130', 'cost =', '0.324713893')\n",
      "('Epoch:', '0131', 'cost =', '0.322460732')\n",
      "('Epoch:', '0132', 'cost =', '0.320212022')\n",
      "('Epoch:', '0133', 'cost =', '0.317934597')\n",
      "('Epoch:', '0134', 'cost =', '0.315633607')\n",
      "('Epoch:', '0135', 'cost =', '0.313375302')\n",
      "('Epoch:', '0136', 'cost =', '0.311160336')\n",
      "('Epoch:', '0137', 'cost =', '0.308960231')\n",
      "('Epoch:', '0138', 'cost =', '0.306768791')\n",
      "('Epoch:', '0139', 'cost =', '0.304583091')\n",
      "('Epoch:', '0140', 'cost =', '0.302404468')\n",
      "('Epoch:', '0141', 'cost =', '0.300235033')\n",
      "('Epoch:', '0142', 'cost =', '0.298075544')\n",
      "('Epoch:', '0143', 'cost =', '0.295926861')\n",
      "('Epoch:', '0144', 'cost =', '0.293789859')\n",
      "('Epoch:', '0145', 'cost =', '0.291665885')\n",
      "('Epoch:', '0146', 'cost =', '0.289556103')\n",
      "('Epoch:', '0147', 'cost =', '0.287462020')\n",
      "('Epoch:', '0148', 'cost =', '0.285384988')\n",
      "('Epoch:', '0149', 'cost =', '0.283326543')\n",
      "('Epoch:', '0150', 'cost =', '0.281288428')\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "total_batches =  len(dataX) // batch_size\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0\n",
    "    train_iter.reset()\n",
    "    for i, data_batch in enumerate(train_iter): \n",
    "        net.forward_backward(data_batch=data_batch)\n",
    "        loss = net.get_outputs()[0].asscalar()\n",
    "        avg_loss += loss /total_batches\n",
    "        net.update()\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Testing\n",
    "\n",
    "Lets define a test network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "expression predicted actual\n",
      "   7+4+3   14        14\n",
      "   6+9+3   18        18\n",
      "   6*4*3   92        72\n",
      "   6*9*2  188       108\n",
      "  4*10*8  340       320\n",
      "   8*4*1   36        32\n",
      "   4+8+2   15        14\n",
      "  10*4*3  160       120\n",
      "   7*5*1   35        35\n",
      "   1*9*1    9         9\n",
      "   6*2*5   60        60\n",
      "   4*9*4  146       144\n",
      "   1+8+9   18        18\n",
      "   9+1+2   12        12\n",
      "   6*9*2  188       108\n",
      "   9*1*2   12        18\n",
      "  10+6+3   10        19\n",
      "   4+8+1   13        13\n",
      "  10*3*8  260       240\n",
      "   3*6*6  198       108\n",
      "   3*4*1   12        12\n",
      "  10+6+8   24        24\n",
      "   3+5+2   10        10\n",
      "   3*6*7  128       126\n",
      "  2+10+8   20        20\n",
      " 8*10*10  800       800\n",
      "   9+1+8   18        18\n",
      "   6+5+9   20        20\n",
      "   6*3*2   32        36\n",
      "  6+10+4   20        20\n",
      "   3+9+6   18        18\n",
      "   4*2*5   40        40\n",
      "   2*3*5   30        30\n",
      "   8*8*5  240       320\n",
      "  10*1*2   20        20\n",
      "  5+10+3   18        18\n",
      "  10+8+4   22        22\n",
      "   1*6*6   36        36\n",
      "   4+2+2    7         8\n",
      "   9*3*7  117       189\n",
      "   5*1*5   25        25\n",
      "  10*1*8   80        80\n",
      "   7+7+5   19        19\n",
      "  10*1*4   40        40\n",
      " 10+5+10   25        25\n",
      "   3*2*5   30        30\n",
      "   3+6+1   10        10\n",
      "   2+6+9   17        17\n",
      "   2*6*8   96        96\n",
      "   4*7*8  244       224\n",
      "   3*1*9   27        27\n",
      "   3+8+6   17        17\n",
      "   4*4*7  128       112\n",
      "   2+8+9   19        19\n",
      "   9*4*2   62        72\n",
      "   1+3+5    9         9\n",
      "  2*10*6  160       120\n",
      "   2+2+6   11        10\n",
      "  10*4*5  200       200\n",
      "   2+3+2    7         7\n",
      "   4*4*8  126       128\n",
      "   1*9*2   12        18\n",
      "   1*7*6   36        42\n",
      "   6+3+1   10        10\n",
      "  10+9+4   23        23\n",
      "  6*10*7  380       420\n",
      "  2+10+4   17        16\n",
      "   6*3*8  146       144\n",
      "  6*10*5  300       300\n",
      "   5*5*4  100       100\n",
      "   2+8+3   13        13\n",
      "   7*8*3  144       168\n",
      "   7+6+9   22        22\n",
      "  10*3*2   60        60\n",
      "   2*8*8  144       128\n",
      "   9*5*7  315       315\n",
      "   1*6*5   30        30\n",
      "   1+2+8   11        11\n",
      "   6+6+9   21        21\n",
      "   3*4*1   12        12\n",
      "   1*7*5   35        35\n",
      "   2*8*6   96        96\n",
      "   3+3+4   10        10\n",
      "   1*3*6   12        18\n",
      "  10+6+3   10        19\n",
      "   3+9+3   15        15\n",
      "   6+6+9   21        21\n",
      "   5*3*7  175       105\n",
      "   6+2+5   13        13\n",
      "   6+1+3   10        10\n",
      "   2*7*1   12        14\n",
      "   9+3+6   18        18\n",
      "   5*2*3   20        30\n",
      "   2*5*9   90        90\n",
      "   9*2*8  144       144\n",
      "   3+5+5   13        13\n",
      "  6*9*10  520       540\n",
      "  5*4*10  200       200\n",
      "   6+7+1   14        14\n",
      "   1*8*8   76        64\n",
      "63 0.63\n"
     ]
    }
   ],
   "source": [
    "# test module\n",
    "test_net = mx.mod.Module(symbol=logits,\n",
    "                         data_names=['data'],\n",
    "                         label_names=None,\n",
    "                         context=mx.gpu()) # FusedRNNCell works only with GPU\n",
    "\n",
    "# data descriptor\n",
    "data_desc = train_iter.provide_data[0]\n",
    "\n",
    "# set shared_module = model used for training so as to share same parameters and memory\n",
    "test_net.bind(data_shapes=[data_desc],\n",
    "              label_shapes=None,\n",
    "              for_training=False,\n",
    "              grad_req='null',\n",
    "              shared_module=net)\n",
    "\n",
    "n_test = 100\n",
    "testX, testY = get_sum_pairs(n_test)\n",
    "\n",
    "testX = np.array(testX, dtype=np.int)\n",
    "\n",
    "test_net.reshape(data_shapes=[mx.io.DataDesc('data', (1, input_seq_length))])\n",
    "predictions = test_net.predict(mx.io.NDArrayIter(testX, batch_size=1)).asnumpy()\n",
    "\n",
    "print(\"expression\", \"predicted\", \"actual\")\n",
    "\n",
    "correct = 0\n",
    "for i, prediction in enumerate(predictions):\n",
    "    x_str = [character_set[j] for j in testX[i]]\n",
    "    index = np.argmax(prediction, axis=1)\n",
    "    result = [character_set[j] for j in index]\n",
    "    label = [character_set[j] for j in testY[i]]\n",
    "    #print(result, label)\n",
    "    if result == label:\n",
    "        correct +=1\n",
    "    print(\"\".join(x_str), \"\".join(result), \"    \", \"\".join(label))\n",
    "    \n",
    "print(correct, correct/(n_test*1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "\n",
    "1. Get 100% accuracy -- Increase training samples? Epochs?\n",
    "2. Try augmenting the input sequence by reversing it. multiplication & addition are commutative\n",
    "3. Create more operators, may be build a generic caluclator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Additional Resources\n",
    "\n",
    "Content was inspired by some of the work below\n",
    "\n",
    "https://github.com/hunkim/DeepLearningZeroToAll/blob/master/mxnet/mxlab-12-5-seq2seq.py   \n",
    "\n",
    "http://machinelearningmastery.com/learn-add-numbers-seq2seq-recurrent-neural-networks/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f4521f13",
   "language": "python",
   "display_name": "PyCharm (timeseries-autoencoder-lstm)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}